{"nbformat_minor": 0, "cells": [{"source": "import urllib\nf = urllib.urlretrieve (\"http://www.analyticscertificate.com/SparkWorkshop/Files/spam.txt\", \"spam.txt\")\nspam_file = \"./spam.txt\"\n\nf = urllib.urlretrieve (\"http://www.analyticscertificate.com/SparkWorkshop/Files/ham.txt\", \"ham.txt\")\nham_file = \"./ham.txt\"\n\nos.getcwd()", "metadata": {"collapsed": false}, "execution_count": 18, "cell_type": "code", "outputs": [{"data": {"text/plain": "'/gpfs/global_fs01/sym_shared/YPProdSpark/user/s82e-9eb5b98d683997-bd809a83de29/notebook/work'"}, "metadata": {}, "execution_count": 18, "output_type": "execute_result"}]}, {"source": "from pyspark import SparkContext\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.mllib.classification import LogisticRegressionWithSGD\nfrom pyspark.mllib.feature import HashingTF", "metadata": {"collapsed": false}, "execution_count": 8, "cell_type": "code", "outputs": []}, {"source": " # Load 2 types of emails from text files: spam and ham (non-spam).\n    # Each line has text from one email.\nspam = sc.textFile(spam_file)\nham = sc.textFile(ham_file)\nspam.take(10)", "metadata": {"collapsed": false}, "execution_count": 19, "cell_type": "code", "outputs": [{"data": {"text/plain": "[u'Dear sir, I am a Prince in a far kingdom you have not heard of.  I want to send you money via wire transfer so please ...',\n u'Get Viagra real cheap!  Send money right away to ...',\n u'Oh my gosh you can be really strong too with these drugs found in the rainforest. Get them cheap right now ...',\n u'YOUR COMPUTER HAS BEEN INFECTED!  YOU MUST RESET YOUR PASSWORD.  Reply to this email with your password and SSN ...',\n u'THIS IS NOT A SCAM!  Send money and get access to awesome stuff really cheap and never have to ...']"}, "metadata": {}, "execution_count": 19, "output_type": "execute_result"}]}, {"source": "ham.take(10)", "metadata": {"collapsed": false}, "execution_count": 20, "cell_type": "code", "outputs": [{"data": {"text/plain": "[u'Dear Spark Learner, Thanks so much for attending the Spark Summit 2014!  Check out videos of talks from the summit at ...',\n u'Hi Mom, Apologies for being late about emailing and forgetting to send you the package.  I hope you and bro have been ...',\n u'Wow, hey Fred, just heard about the Spark petabyte sort.  I think we need to take time to try it out immediately ...',\n u'Hi Spark user list, This is my first question to this list, so thanks in advance for your help!  I tried running ...',\n u\"Thanks Tom for your email.  I need to refer you to Alice for this one.  I haven't yet figured out that part either ...\",\n u'Good job yesterday!  I was attending your talk, and really enjoyed it.  I want to try out GraphX ...',\n u'Summit demo got whoops from audience!  Had to let you know. --Joe']"}, "metadata": {}, "execution_count": 20, "output_type": "execute_result"}]}, {"source": "# Create a HashingTF instance to map email text to vectors of 100 features.\ntf = HashingTF(numFeatures = 100)\n# Each email is split into words, and each word is mapped to one feature.\nspamFeatures = spam.map(lambda email: tf.transform(email.split(\" \")))\nhamFeatures = ham.map(lambda email: tf.transform(email.split(\" \")))", "metadata": {"collapsed": true}, "execution_count": 21, "cell_type": "code", "outputs": []}, {"source": "# Create LabeledPoint datasets for positive (spam) and negative (ham) examples.\npositiveExamples = spamFeatures.map(lambda features: LabeledPoint(1, features))\nnegativeExamples = hamFeatures.map(lambda features: LabeledPoint(0, features))\ntraining_data = positiveExamples.union(negativeExamples)\ntraining_data.cache() # Cache data since Logistic Regression is an iterative algorithm.", "metadata": {"collapsed": false}, "execution_count": 22, "cell_type": "code", "outputs": [{"data": {"text/plain": "UnionRDD[41] at union at NativeMethodAccessorImpl.java:-2"}, "metadata": {}, "execution_count": 22, "output_type": "execute_result"}]}, {"source": "# Run Logistic Regression using the SGD optimizer.\n# regParam is model regularization, which can make models more robust.\nmodel = LogisticRegressionWithSGD.train(training_data)", "metadata": {"collapsed": true}, "execution_count": 23, "cell_type": "code", "outputs": []}, {"source": "# Test on a positive example (spam) and a negative one (ham).\n# First apply the same HashingTF feature transformation used on the training data.\nposTestExample = tf.transform(\"O M G GET cheap stuff by sending money to ...\".split(\" \"))\nnegTestExample = tf.transform(\"Hi Dad, I started studying Spark the other ...\".split(\" \"))", "metadata": {"collapsed": true}, "execution_count": 24, "cell_type": "code", "outputs": []}, {"source": "# Now use the learned model to predict spam/ham for new emails.\nprint \"Prediction for positive test example: %g\" % model.predict(posTestExample)\nprint \"Prediction for negative test example: %g\" % model.predict(negTestExample)", "metadata": {"collapsed": false}, "execution_count": 25, "cell_type": "code", "outputs": [{"name": "stdout", "text": "Prediction for positive test example: 1\nPrediction for negative test example: 0\n", "output_type": "stream"}]}], "nbformat": 4, "metadata": {"kernelspec": {"name": "python2", "language": "python", "display_name": "Python 2"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 2}, "name": "python", "pygments_lexer": "ipython2", "mimetype": "text/x-python", "version": "2.7.11", "file_extension": ".py", "nbconvert_exporter": "python"}}}